{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'mode' is missing. Valid modes are ('train', 'val', 'predict', 'export', 'track', 'benchmark'). Using default 'mode=train'.\n",
      "WARNING  'data' is missing. Using default 'data=coco8-pose.yaml'.\n",
      "Ultralytics YOLOv8.0.124  Python-3.9.12 torch-2.0.1+cpu CPU\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=pose, mode=train, model=yolov8n-pose.pt, data=coco8-pose.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=C:\\Users\\Yerkhat\\Downloads\\photo_2023-09-23_13-12-56.jpg, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\pose\\train\n",
      "\n",
      "Dataset 'coco8-pose.yaml' images not found , missing paths ['C:\\\\Users\\\\Yerkhat\\\\Downloads\\\\datasets\\\\coco8-pose\\\\images\\\\val']\n",
      "Downloading https:\\ultralytics.com\\assets\\coco8-pose.zip to C:\\Users\\Yerkhat\\Downloads\\datasets\\coco8-pose.zip...\n",
      "\n",
      "  0%|          | 0.00/334k [00:00<?, ?B/s]\n",
      "  5%|▍         | 16.0k/334k [00:00<00:02, 119kB/s]\n",
      " 24%|██▍       | 80.0k/334k [00:00<00:00, 373kB/s]\n",
      " 72%|███████▏  | 240k/334k [00:00<00:00, 868kB/s] \n",
      "100%|██████████| 334k/334k [00:00<00:00, 880kB/s]\n",
      "Unzipping C:\\Users\\Yerkhat\\Downloads\\datasets\\coco8-pose.zip to C:\\Users\\Yerkhat\\Downloads\\datasets...\n",
      "Dataset download success  (2.7s), saved to \u001b[1mC:\\Users\\Yerkhat\\Downloads\\datasets\u001b[0m\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1035934  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n",
      "YOLOv8n-pose summary: 250 layers, 3295470 parameters, 3295454 gradients\n",
      "\n",
      "Transferred 397/397 items from pretrained weights\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Yerkhat\\Downloads\\datasets\\coco8-pose\\labels\\train...:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Yerkhat\\Downloads\\datasets\\coco8-pose\\labels\\train... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 153.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Yerkhat\\Downloads\\datasets\\coco8-pose\\labels\\train.cache\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Yerkhat\\Downloads\\datasets\\coco8-pose\\labels\\val...:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Yerkhat\\Downloads\\datasets\\coco8-pose\\labels\\val... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 225.32it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Yerkhat\\Downloads\\datasets\\coco8-pose\\labels\\val.cache\n",
      "Plotting labels to runs\\pose\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\pose\\train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
      "OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.\n"
     ]
    }
   ],
   "source": [
    "#!yolo model=yolov8n-pose.pt source=\"C:\\Users\\Yerkhat\\Downloads\\photo_2023-09-23_13-12-56.jpg\"   # load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"YOLOv8n-pose.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: 0... Success  (inf frames of shape 640x480 at 30.00 FPS)\n",
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 480x640 1 person, 162.5ms\n",
      "0: 480x640 1 person, 139.7ms\n",
      "0: 480x640 1 person, 129.2ms\n",
      "0: 480x640 1 person, 133.5ms\n",
      "0: 480x640 1 person, 131.3ms\n",
      "0: 480x640 1 person, 129.8ms\n",
      "0: 480x640 1 person, 133.1ms\n",
      "0: 480x640 1 person, 132.1ms\n",
      "0: 480x640 1 person, 127.1ms\n",
      "0: 480x640 1 person, 129.0ms\n",
      "0: 480x640 1 person, 130.8ms\n",
      "0: 480x640 1 person, 124.8ms\n",
      "0: 480x640 1 person, 128.5ms\n",
      "0: 480x640 1 person, 140.6ms\n",
      "0: 480x640 1 person, 141.4ms\n",
      "0: 480x640 1 person, 129.8ms\n",
      "0: 480x640 1 person, 136.4ms\n",
      "0: 480x640 1 person, 121.1ms\n",
      "0: 480x640 1 person, 125.1ms\n",
      "0: 480x640 1 person, 134.5ms\n",
      "0: 480x640 1 person, 138.2ms\n",
      "0: 480x640 1 person, 125.3ms\n",
      "0: 480x640 1 person, 121.5ms\n",
      "0: 480x640 1 person, 129.3ms\n",
      "0: 480x640 1 person, 121.0ms\n",
      "0: 480x640 1 person, 122.5ms\n",
      "0: 480x640 1 person, 121.2ms\n",
      "0: 480x640 1 person, 127.0ms\n",
      "0: 480x640 1 person, 121.4ms\n",
      "0: 480x640 1 person, 121.1ms\n",
      "0: 480x640 1 person, 119.7ms\n",
      "0: 480x640 1 person, 121.2ms\n",
      "0: 480x640 1 person, 119.4ms\n",
      "0: 480x640 1 person, 121.4ms\n",
      "0: 480x640 1 person, 122.2ms\n",
      "0: 480x640 1 person, 114.8ms\n",
      "0: 480x640 1 person, 122.2ms\n",
      "0: 480x640 1 person, 118.0ms\n",
      "0: 480x640 1 person, 119.5ms\n",
      "0: 480x640 1 person, 124.3ms\n",
      "0: 480x640 1 person, 122.9ms\n",
      "0: 480x640 1 person, 118.4ms\n",
      "0: 480x640 1 person, 113.5ms\n",
      "0: 480x640 1 person, 125.6ms\n",
      "0: 480x640 1 person, 120.3ms\n",
      "0: 480x640 1 person, 122.3ms\n",
      "0: 480x640 1 person, 131.2ms\n",
      "0: 480x640 1 person, 136.4ms\n",
      "0: 480x640 1 person, 122.8ms\n",
      "0: 480x640 1 person, 119.5ms\n",
      "0: 480x640 1 person, 121.4ms\n",
      "0: 480x640 1 person, 117.8ms\n",
      "0: 480x640 1 person, 116.5ms\n",
      "0: 480x640 1 person, 118.7ms\n",
      "0: 480x640 1 person, 117.5ms\n",
      "0: 480x640 1 person, 114.1ms\n",
      "0: 480x640 1 person, 116.8ms\n",
      "0: 480x640 1 person, 123.5ms\n",
      "0: 480x640 1 person, 121.6ms\n",
      "0: 480x640 1 person, 122.3ms\n",
      "0: 480x640 1 person, 126.5ms\n",
      "0: 480x640 1 person, 122.4ms\n",
      "0: 480x640 1 person, 116.9ms\n",
      "0: 480x640 1 person, 118.1ms\n",
      "0: 480x640 1 person, 123.4ms\n",
      "0: 480x640 1 person, 119.5ms\n",
      "0: 480x640 1 person, 119.2ms\n",
      "0: 480x640 1 person, 121.5ms\n",
      "0: 480x640 1 person, 122.2ms\n",
      "0: 480x640 1 person, 122.8ms\n",
      "0: 480x640 1 person, 121.8ms\n",
      "0: 480x640 1 person, 126.3ms\n",
      "0: 480x640 1 person, 125.1ms\n",
      "0: 480x640 1 person, 123.2ms\n",
      "0: 480x640 1 person, 120.9ms\n",
      "0: 480x640 1 person, 122.5ms\n",
      "0: 480x640 1 person, 107.4ms\n",
      "0: 480x640 1 person, 121.3ms\n",
      "0: 480x640 1 person, 119.5ms\n",
      "0: 480x640 1 person, 120.3ms\n",
      "0: 480x640 1 person, 120.5ms\n",
      "0: 480x640 1 person, 123.4ms\n",
      "0: 480x640 1 person, 120.5ms\n",
      "0: 480x640 1 person, 116.5ms\n",
      "0: 480x640 1 person, 114.5ms\n",
      "0: 480x640 1 person, 118.3ms\n",
      "0: 480x640 1 person, 134.9ms\n",
      "0: 480x640 1 person, 125.0ms\n",
      "0: 480x640 1 person, 118.9ms\n",
      "0: 480x640 1 person, 127.6ms\n",
      "0: 480x640 1 person, 125.2ms\n",
      "0: 480x640 1 person, 125.0ms\n",
      "0: 480x640 1 person, 118.3ms\n",
      "0: 480x640 1 person, 114.0ms\n",
      "0: 480x640 1 person, 126.2ms\n",
      "0: 480x640 1 person, 119.0ms\n",
      "0: 480x640 1 person, 122.1ms\n",
      "0: 480x640 1 person, 124.5ms\n",
      "0: 480x640 1 person, 124.0ms\n",
      "0: 480x640 1 person, 129.5ms\n",
      "0: 480x640 1 person, 132.9ms\n",
      "0: 480x640 1 person, 130.2ms\n",
      "0: 480x640 1 person, 131.6ms\n",
      "0: 480x640 1 person, 138.0ms\n",
      "0: 480x640 1 person, 129.9ms\n",
      "0: 480x640 1 person, 130.8ms\n",
      "0: 480x640 1 person, 155.8ms\n",
      "0: 480x640 1 person, 126.5ms\n",
      "0: 480x640 1 person, 129.4ms\n",
      "0: 480x640 1 person, 128.7ms\n",
      "0: 480x640 1 person, 132.4ms\n",
      "0: 480x640 1 person, 134.0ms\n",
      "0: 480x640 1 person, 127.0ms\n",
      "0: 480x640 1 person, 137.1ms\n",
      "0: 480x640 1 person, 130.9ms\n",
      "0: 480x640 1 person, 122.5ms\n",
      "0: 480x640 1 person, 120.4ms\n",
      "0: 480x640 1 person, 121.2ms\n",
      "0: 480x640 1 person, 121.3ms\n",
      "0: 480x640 1 person, 128.4ms\n",
      "0: 480x640 1 person, 125.9ms\n",
      "0: 480x640 1 person, 130.7ms\n",
      "0: 480x640 1 person, 121.9ms\n",
      "0: 480x640 1 person, 122.2ms\n",
      "0: 480x640 1 person, 124.7ms\n",
      "0: 480x640 1 person, 123.1ms\n",
      "0: 480x640 1 person, 125.0ms\n",
      "0: 480x640 1 person, 127.4ms\n",
      "0: 480x640 1 person, 126.5ms\n",
      "0: 480x640 1 person, 124.8ms\n",
      "0: 480x640 1 person, 122.4ms\n",
      "0: 480x640 1 person, 127.4ms\n",
      "0: 480x640 1 person, 134.1ms\n",
      "0: 480x640 1 person, 142.6ms\n",
      "0: 480x640 1 person, 119.4ms\n",
      "0: 480x640 1 person, 128.2ms\n",
      "0: 480x640 1 person, 126.6ms\n",
      "0: 480x640 1 person, 131.6ms\n",
      "0: 480x640 1 person, 137.8ms\n",
      "0: 480x640 1 person, 140.5ms\n",
      "0: 480x640 1 person, 132.4ms\n",
      "0: 480x640 1 person, 127.9ms\n",
      "0: 480x640 1 person, 128.9ms\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "source = \"C:/Users/Yerkhat/Downloads/GettyImages-1459166551-ce898f4cd2e04caab74bf5e6ba108605 (1).jpg\"  # path to folder or file (imaages, videos)\n",
    "img = model.predict(source = 0, imgsz=640, conf=0.5, show=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
